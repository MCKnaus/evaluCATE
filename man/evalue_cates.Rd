% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cates-evaluation.R
\name{evalue_cates}
\alias{evalue_cates}
\title{CATEs Evaluation}
\usage{
evalue_cates(
  Y,
  D,
  X,
  cates,
  is_train,
  pscore = NULL,
  mu = NULL,
  mu0 = NULL,
  mu1 = NULL,
  n_groups = 5,
  verbose = TRUE
)
}
\arguments{
\item{Y}{Observed outcomes.}

\item{D}{Treatment indicator.}

\item{X}{Covariate matrix (no intercept).}

\item{cates}{Estimated CATEs. Must be estimated using only the training sample.}

\item{is_train}{Logical vector denoting which observations belong to the training sample.}

\item{pscore}{Propensity scores. If unknown, they must be estimated using only the training sample.}

\item{mu}{Estimated regression function. Must be estimated using only the training sample.}

\item{mu0}{Estimated regression function for control units. Must be estimated using only the training sample.}

\item{mu1}{Estimated regression function for treated units. Must be estimated using only the training sample.}

\item{n_groups}{Number of groups to be formed for the GATES analysis.}

\item{verbose}{Logical, set to FALSE to prevent the function from printing the progresses.}
}
\value{
Return.
}
\description{
Evaluates the quality of CATEs estimates by implementing several Generic Machine Learning methodologies.
}
\details{
\code{\link{evalue_cates}} targets the estimation of the best linear predictor (BLP) of the actual CATEs using the estimated CATEs and of the sorted group average treatment effects (GATES).
To this end, the user must provide observations on the outcomes, the treatment status, and the covariates of units in the whole sample, as well as their estimated CATEs. Be careful,
as the CATEs must be estimated only with part of the sample, which we call the training sample (see the example section below).\cr

To let the function know which observations were used for the CATEs estimation, the user must also provide a logical vector with the \code{TRUE}s denoting observations in the
training sample. This way, \code{\link{evalue_cates}} knows which observations to use to post-process the CATEs estimates.\cr

\code{\link{evalue_cates}} implements a number of strategies to estimate the BLP and the GATES. Most of them involve fitting a suitable linear model. The linear models differ according to the
different identification strategies. Furthermore, for each strategy, there exist various sets of constructed covariates that one can add to reduce the variance of the estimation. \code{\link{evalue_cates}}
fits and returns all these possible models. Check the online \href{https://riccardo-df.github.io/evaluCATE/articles/evalue-cates-short-tutorial.html}{short tutorial} for details.\cr

Some of these models involve covariates that depend on particular nuisance functions, e.g., propensity score and conditional mean of the outcome (check the online \href{https://riccardo-df.github.io/evaluCATE/articles/denoising.html}{denoising vignette}
for details about these covariates.). The user can supply estimates of these functions by using the optional arguments \code{pscore}, \code{mu}, \code{mu0}, and \code{mu1}. Be careful, as these must be obtained using
only the training sample. If not provided by the user, these functions are estimated internally via honest \code{\link[grf]{regression_forest}}s. \cr

For the linear models, standard errors are estimated using the Eicker-Huber-White estimator.\cr

To estimate the BLP and GATES using the AIPW strategy, doubly-robust scores are estimated internally using the validation sample via 5-fold cross fitting and honest regression
forests (see the \code{\link[aggTrees]{dr_scores}} function).\cr

The estimated GATES are sorted to enforce monotonicity.
}
\examples{
## Generate data.
set.seed(1986)

n <- 1000
k <- 2

X <- matrix(rnorm(n * k), ncol = k)
colnames(X) <- paste0("x", seq_len(k))
D <- rbinom(n, size = 1, prob = 0.5)
mu0 <- 0.5 * X[, 1]
mu1 <- 0.5 * X[, 1] + X[, 2]
Y <- mu0 + D * (mu1 - mu0) + rnorm(n)

## Sample split.
train_idx <- sample(c(TRUE, FALSE), length(Y), replace = TRUE)

X_tr <- X[train_idx, ]
X_val <- X[!train_idx, ]

D_tr <- D[train_idx]
D_val <- D[!train_idx]

Y_tr <- Y[train_idx]
Y_val <- Y[!train_idx]

## CATEs estimation.
library(grf)

forest <- causal_forest(X_tr, Y_tr, D_tr) # We use only the training sample.
cates <- predict(forest, X)$predictions # We predict on the whole sample.

## CATEs evaluation. Estimate all nuisances internally. 
pscore <- rep(0.5, length(Y))
evaluation <- evalue_cates(Y, D, X, cates, train_idx, pscore = pscore)

## Compare results for a given model.
blp_model <- evaluation$BLP$aipw
gates_model <- evaluation$GATES$aipw

# True ATE vs estimated ATE.
cat("True ATE      : ", round(mean(mu1 - mu0), 3), " 
Estimated ATE : ", round(blp_model$coefficients["beta1"], 3), " [", round(blp_model$conf.low["beta1"], 3), ", ", round(blp_model$conf.high["beta1"], 3), "]", sep = "")

# True "quality" of estimated CATEs vs estimated quality.
# (We can do this because we know that, by DGP, we have heterogeneous effects.)
cat("True quality      : ", cor(mu1[!train_idx] - mu0[!train_idx], cates[!train_idx]), " 
Estimated quality : ", round(blp_model$coefficients["beta2"], 3), " [", round(blp_model$conf.low["beta2"], 3), ", ", round(blp_model$conf.high["beta2"], 3), "]", sep = "") 

# True GATES with estimated GATES.
n_groups <- length(coef(evaluation$GATES$aipw))
cuts <- seq(0, 1, length = n_groups+1)[-c(1, n_groups+1)]
group_indicators <- GenericML::quantile_group(cates[!train_idx], cutoffs = cuts)
colnames(group_indicators) <- paste0(1:n_groups)
true_gates <- apply(group_indicators, 2, function(x) {mean(cates[!train_idx][x])})

library(ggplot2)

plot_dta <- data.frame("group" = 1:n_groups, "true_gate" = true_gates, 
                       "estimated_gate" = gates_model$coefficients[1:n_groups], 
                       "se" = gates_model$std.error[1:n_groups])

ggplot(plot_dta, aes(x = group, y = true_gate)) +
  geom_point(aes(color = "True")) +
  geom_point(aes(y = estimated_gate, color = "Estimated")) +
  geom_errorbar(aes(x = group, ymin = estimated_gate - 1.96 * se, ymax = estimated_gate + 1.96 * se), color = "black") +
  xlab("Group") + ylab("GATES") + 
  scale_color_manual(name = "", breaks = c("True", "Estimated"), values = c("True" = "tomato", "Estimated" = "dodgerblue")) +
  theme_bw() + 
  theme(legend.position = c(0.2, 0.85))

}
\seealso{
Other functions
}
\author{
Riccardo Di Francesco
}
