% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cates-evaluation.R
\name{evalue_cates}
\alias{evalue_cates}
\title{CATEs Evaluation}
\usage{
evalue_cates(
  y,
  D,
  X,
  cates,
  is_train,
  pscore = NULL,
  n_groups = 5,
  verbose = TRUE
)
}
\arguments{
\item{y}{Observed outcomes.}

\item{D}{Treatment indicator.}

\item{X}{Covariate matrix (no intercept).}

\item{cates}{Estimated CATEs. CATEs must be estimated using only the training sample.}

\item{is_train}{Logical vector denoting which observations belong to the training sample.}

\item{pscore}{Propensity scores. If unknown, they must be estimated using only the training sample. If not provided by the user, they are estimated internally via an honest \code{\link[grf]{regression_forest}}.}

\item{n_groups}{Number of groups to be formed.}

\item{verbose}{Logical, set to FALSE to prevent the function from printing the progresses.}
}
\value{
Return.
}
\description{
Evaluates the quality of CATEs estimates by implementing several Generic Machine Learning methodologies.
}
\details{
\code{\link{evalue_cates}} targets the estimation of the best linear predictor (BLP) of the actual CATEs using the estimated CATEs and of the sorted group average treatment effects (GATES).
To this end, the user must provide observations on the outcomes, the treatment status, and the covariates of units in the whole sample, as well as their estimated CATEs. Be careful,
as the CATEs must be estimated only with part of the sample, which we call the training sample (see the example section below).\cr

To let the function know which observations were used for the CATEs estimation, the user must also provide a logical vector with the \code{TRUE}s denoting observations in the
training sample. This way, \code{\link{evalue_cates}} knows which observations to use to post-process the CATEs estimates.\cr

\code{\link{evalue_cates}} implements a number of strategies to estimate the BLP and the GATES. Most of them involve fitting a suitable linear model. The linear models differ according to the
different strategies. Furthermore, for each strategy, there exist various sets of constructed covariates that one can add to reduce the variance of the estimation. \code{\link{evalue_cates}}
fits and returns all these possible models. Check the online \href{https://riccardo-df.github.io/evalueCATE/articles/evalue-cates-short-tutorial.html}{short tutorial} for details.\cr

Some of these models involve covariates that depend on particular nuisance functions. These functions are estimated internally via honest \code{\link[grf]{regression_forest}}s.
Check the online \href{https://riccardo-df.github.io/evalueCATE/articles/denoising.html}{denoising vignette} for details about these covariates.\cr

For the linear models, standard errors are estimated using the Eicker-Huber-White estimator.\cr

To estimate the BLP and GATES using the AIPW strategy, doubly-robust scores are estimated internally using the validation sample via 5-fold cross fitting and honest regression
forests (see the \code{\link[aggTrees]{dr_scores}} function).\cr

The estimated GATES are sorted to enforce monotonicity.
}
\examples{
## Generate data.
set.seed(1986)

n <- 1000
k <- 2

X <- matrix(rnorm(n * k), ncol = k)
colnames(X) <- paste0("x", seq_len(k))
D <- rbinom(n, size = 1, prob = 0.5)
mu0 <- 0.5 * X[, 1]
mu1 <- 0.5 * X[, 1] + X[, 2]
y <- mu0 + D * (mu1 - mu0) + rnorm(n)

## Sample split.
train_idx <- sample(c(TRUE, FALSE), length(y), replace = TRUE)

X_tr <- X[train_idx, ]
X_val <- X[!train_idx, ]

D_tr <- D[train_idx]
D_val <- D[!train_idx]

y_tr <- y[train_idx]
y_val <- y[!train_idx]

## CATEs estimation.
library(grf)

forest <- causal_forest(X_tr, y_tr, D_tr) # We use only the training sample.
cates <- predict(forest, X)$predictions # We predict on the whole sample.

## CATEs evaluation.  
pscore <- rep(0.5, length(y_val))
n_groups <- 5

evaluation <- evalue_cates(y, D, X, cates, train_idx, pscore, n_groups)

## Compare results for a given model.
blp_model <- evaluation$BLP$aipw
gates_model <- evaluation$GATES$aipw

# True ATE vs estimated ATE.
cat("True ATE      : ", round(mean(mu1 - mu0), 3), " 
Estimated ATE : ", round(blp_model$coefficients["beta1"], 3), " [", round(blp_model$conf.low["beta1"], 3), ", ", round(blp_model$conf.high["beta1"], 3), "]", sep = "")

# True "quality" of estimated CATEs vs estimated quality.
# (We can do this because we know that, by DGP, we have heterogeneous effects.)
cat("True quality      : ", cor(mu1[!train_idx] - mu0[!train_idx], cates[!train_idx]), " 
Estimated quality : ", round(blp_model$coefficients["beta2"], 3), " [", round(blp_model$conf.low["beta2"], 3), ", ", round(blp_model$conf.high["beta2"], 3), "]", sep = "") 

# True GATES with estimated GATES.
cuts <- seq(0, 1, length = n_groups+1)[-c(1, n_groups+1)]
group_indicators <- GenericML::quantile_group(cates[!train_idx], cutoffs = cuts)
colnames(group_indicators) <- paste0(1:n_groups)
true_gates <- apply(group_indicators, 2, function(x) {mean(cates[!train_idx][x])})

library(ggplot2)

plot_dta <- data.frame("group" = 1:n_groups, "true_gate" = true_gates, 
                       "estimated_gate" = gates_model$coefficients[1:n_groups], 
                       "se" = gates_model$std.error[1:n_groups])

ggplot(plot_dta, aes(x = group, y = true_gate)) +
  geom_point(aes(color = "True")) +
  geom_point(aes(y = estimated_gate, color = "Estimated")) +
  geom_errorbar(aes(x = group, ymin = estimated_gate - 1.96 * se, ymax = estimated_gate + 1.96 * se), color = "black") +
  xlab("Group") + ylab("GATES") + 
  scale_color_manual(name = "", breaks = c("True", "Estimated"), values = c("True" = "tomato", "Estimated" = "dodgerblue")) +
  theme_bw() + 
  theme(legend.position = c(0.2, 0.85))

}
\seealso{
Other functions
}
\author{
Riccardo Di Francesco
}
